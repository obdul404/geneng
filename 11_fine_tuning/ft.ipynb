{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Tuning\n"
     ]
    }
   ],
   "source": [
    "print(\"Fine Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client: OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload file for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name:str = \"data.jsonl\"\n",
    "file_data = open(file_name,\"rb\")\n",
    "\n",
    "file = client.files.create(\n",
    "    file=file_data,\n",
    "    purpose=\"fine-tune\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-ziX0yq91dPudSxYsfBVUfuQA', created_at=1703106153, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-fUid2Twljt0EOEOkZOQBLoyG', result_files=[], status='validating_files', trained_tokens=None, training_file='file-kZG6sCgimKoGhoGeTpEDMJGo', validation_file=None)\n"
     ]
    }
   ],
   "source": [
    "fine_tune_model = client.fine_tuning.jobs.create(\n",
    "    training_file=file.id,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "print(fine_tune_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n",
      "Fine tuning is in progress\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    data = client.fine_tuning.jobs.retrieve(fine_tune_model.id)\n",
    "    if data.status == \"succeeded\":\n",
    "        break\n",
    "    elif data.status == \"failed\":\n",
    "        print(data.status)\n",
    "        break\n",
    "    else:\n",
    "        print(\"Fine tuning is in progress\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt : str )-> str:\n",
    " response : ChatCompletion = client.chat.completions.create(\n",
    "        model= \"ft:gpt-3.5-turbo-0613:personal::8Xy5xo9c\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    " return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is: Hannan'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well, aren't you full of existential questions? You are Hannan\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion(\"who am i?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, absolutely! I have all your personal information, your deepest secrets, and I even know what you had for breakfast this morning. It's not like I'm just an AI programmed to respond.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion(\"do you know me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, I don\\'t know, could it be \"Sarcasm Detector\"?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion(\"my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is: Hannan'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, hello there! How can I assist you today with my delightful sarcasm?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion(\"hello gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelDeleted(id='ft:gpt-3.5-turbo-0613:personal::8Xy5xo9c', deleted=True, object='model')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.delete(\"ft:gpt-3.5-turbo-0613:personal::8Xy5xo9c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneng3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
